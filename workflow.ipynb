{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DrugEx API\n",
    "\n",
    "An example DrugEx workflow showcasing some basic DrugEx API features. The API provides interface definitions to handle data operations and training of models needed for obtaining a molecule designer. The interface should ensure that the current code base is extensible and loosely coupled to make interoperability with different data sources seamless and to also aid in monitoring of the training processes involved.\n",
    "\n",
    "Let's import and explain some of the important API features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main package\n",
    "import drugex\n",
    "\n",
    "# important classes for data access\n",
    "from drugex.api.environ.data import ChEMBLCSV\n",
    "from drugex.api.corpus import CorpusCSV, BasicCorpus, CorpusChEMBL\n",
    "\n",
    "# important classes for QSAR modelling\n",
    "# and (de)serialization of QSAR models\n",
    "from drugex.api.environ.models import RF\n",
    "from drugex.api.environ.serialization import FileEnvSerializer, FileEnvDeserializer\n",
    "\n",
    "# classes that handle training of the exploration\n",
    "# and exploitation networks and also handle monitoring \n",
    "# of the process \n",
    "from drugex.api.model.callbacks import BasicMonitor\n",
    "from drugex.api.pretrain.generators import BasicGenerator\n",
    "\n",
    "# ingredients needed for DrugEx agent training\n",
    "from drugex.api.agent.agents import DrugExAgent\n",
    "from drugex.api.agent.callbacks import BasicAgentMonitor\n",
    "from drugex.api.agent.policy import PG\n",
    "\n",
    "# designer API (wraps the agent after it was trained)\n",
    "from drugex.api.designer.designers import BasicDesigner, CSVConsumer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's define some global settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (3, 5)\n",
      "1 (2, 1)\n",
      "2 (3, 5)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "for device in range(torch.cuda.device_count()):\n",
    "    print(device, torch.cuda.get_device_capability(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # choose a GPU device based on the info above\n",
    "    # (the higher the capability, the better)\n",
    "    torch.cuda.set_device(2)\n",
    "\n",
    "DATA_DIR=\"data\" # folder with input data files\n",
    "OUT_DIR=\"output/workflow\" # folder to store the output of this workflow\n",
    "os.makedirs(OUT_DIR, exist_ok=True) # create the output folder\n",
    "\n",
    "# define a set of gene IDs that are interesting for \n",
    "# the target that we want to design molecules for\n",
    "GENE_IDS = [\"ADORA2A\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Aquisition\n",
    "\n",
    "It's time to aquire the data we will need for training of our models. There are three models that we need to build so we need three separate data sets:\n",
    "\n",
    "1. Data for the exploitation model based on a random sample of 1 million molecules from the ZINC set.\n",
    "2. Data for the exploration model based on ChEMBL data we downloaded for the desired target.\n",
    "3. Data for the QSAR modelling of the environment model -> this model will bias the final generator towards more active molecules throug the a policy gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly selected sample of 1 million molecules\n",
    "# from the ZINC database.\n",
    "# We only use this file for illustration purposes.\n",
    "# In practice, the pretrained exploitation network will always\n",
    "# be provided so there will be no need for this data,\n",
    "# but we are starting from square one here.\n",
    "ZINC_CSV=os.path.join(DATA_DIR, \"ZINC.txt\")\n",
    "\n",
    "# Load structure data into a corpus from a CSV file (we assume\n",
    "# that we have the structures saved in a csv file in DATA_DIR).\n",
    "# This corpus will be used to train the exploitation network later.\n",
    "corpus_pre = CorpusCSV(\n",
    "    update_file=ZINC_CSV\n",
    "    # The input CSV file we will use to update the data in this corpus.\n",
    "\n",
    "    , vocabulary=drugex.VOC_DEFAULT\n",
    "    # The vocabulary object that defines the tokens\n",
    "    # and other options used to construct and parse SMILES.\n",
    "    # VOC_DEFAULT is a reasonable \"catch all\" default.\n",
    "\n",
    "    , smiles_column=\"CANONICAL_SMILES\"\n",
    "    # Tells the corpus object what column to look for when\n",
    "    # extracting SMILES to update the data.\n",
    "\n",
    "    , sep='\\t'\n",
    "    # The column separator used in the CSV file\n",
    ")\n",
    "\n",
    "# Now we update the corpus (if we did not do it already).\n",
    "# It loads and tokenizes the SMILES it finds in the CSV.\n",
    "# The tokenized data and updated vocabulary are returned to us.\n",
    "corpus_out_zinc = os.path.join(OUT_DIR, \"zinc_corpus.txt\")\n",
    "vocab_out_zinc = os.path.join(OUT_DIR, \"zinc_voc.txt\")\n",
    "if not os.path.exists(corpus_out_zinc):\n",
    "    df, voc = corpus_pre.updateData(update_voc=True)\n",
    "    # We don't really use the return values here, but they are\n",
    "    # still there if we need them for logging purposes or\n",
    "    # something else.\n",
    "\n",
    "    # All that remains is to just save our corpus data\n",
    "    # so that we don't have to recalculate it again.\n",
    "    # The CorpusCSV class has a method for that so lets use it.\n",
    "    corpus_pre.saveCorpus(corpus_out_zinc)\n",
    "    corpus_pre.saveVoc(vocab_out_zinc)\n",
    "else:\n",
    "    # if we already initialized and saved\n",
    "    # the corpus before, we just overwrite the\n",
    "    # current one with the saved one\n",
    "    corpus_pre= CorpusCSV.fromFiles(corpus_out_zinc, vocab_out_zinc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
